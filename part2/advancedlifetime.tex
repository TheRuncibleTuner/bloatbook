\chapter{Customization and Tuning: Advanced Lifetime Management Techniques}
\label{chapter:advanced-lifetime-techniques}

\begin{comment}

\section{Understanding and Tuning the Garbage Collector}

\paragraph{The Collection Schedule and Safe Points}
The garbage collector does not reclaim memory immediately after an object's last
use. Instead, to amortize the costs involved in reclamation, the garbage
collector often lets reclaimable objects pile up for a while, and reclaims memory
in bulk. This bulk operation or reclaiming unused memory is usually implemented
as a number of threads. These worker threads, on some schedule, wake up and
traverse the heap for live objects. As objects are allocated, memory consumption
can be observed to increase, up until some maximum allowed amount. At this point,
the collector reclaims unused memory, and the process starts again. In this way,
memory consumption over time often assumes a sawtooth edge, such as those shown
in \autoref{fig:timeline-base-session-temps-with-cache}.
\index{Sawtooth Pattern}

\paragraph{GC Safe Points}
\index{Safe Points, use for Garbage Collection}

In most production \jres, garbage collection is, in normal execution, not run at
arbitrary points in the code. For example, in the above method \code{Foo.bar},
even though the object referred to by \code{localVariableReference1} becomes
unreachable before the end of the invocation, most \jres will not notice this
until a period of time after the assignment to \code{null} at line 6. This delay
comes about because the garbage collector typically only runs when threads reach
certain \emph{safe points} in the code. Safe points commonly include the
beginning or end of method invocations, the end of each loop iteration, and
points surrounding native method invocations. Therefore, the earliest time at
which the object referred to by \code{localVariableReference1} could be reclaimed
is after the first iteration of the loop; it could even possibly be the end of
the invocation, if the loop iterates zero times.

This is not to say that the garbage collector runs at every safe point, or that
it waits for all threads to reach a safe point before proceeding. Any thread that
tries, but fails, to allocate a new object will of course result in a garbage
collection at whatever line of code that allocation is found. At that point in
time, the other threads will continue executing up until their next safe point,
or their own failure to allocate memory, at which point garbage collection can
proceed.

\paragraph{Configuration Settings}
You can guide the frequency of collection, which will change the slope of this
sawtooth curve to be either more or less jagged. In one common case, the garbage
collector will wait until all available memory is consumed before reclaiming
storage.  In Java, you can configure this ceiling by supplying a sizing to the
\code{-Xms} (initial ceiling) and
\code{-Xmx} (maximum ceiling) command line options. \index{-Xms command line setting}
\index{-Xmx command line setting} The \jre will begin with a ceiling at the
former level. If collections are occuring too frequently, the \jre may decide to
increase the \emph{current} ceiling to a higher level. As the need for memory
fluctuates, so the \jre will raise or lower the current ceiling level. The
current ceiling will always be some value lower than the maximum, \code{-Xmx},
setting. One such scenario, of increasing ceiling level, is illustrated in
\autoref{fig:timeline-base-session-temps-with-leak}.

\paragraph{The Nursery and Mature Heaps}
\index{Nursery}

\begin{figure}
\centering
	\includegraphics[width=0.6\textwidth]{part2/Figures/lifetime/nursery}
	\caption{Oftentimes, the Java heap is split into two sub-heaps. The nursery
	space stores newly-allocated objects, and the mature space stores objects that
	have been tenured. The garbage collector tenures an object after it
	survives a sufficient number of nursery garbage collections.}
	\label{fig:nursery-and-mature}
\end{figure}

To optimize for applications that create a large number of temporary objects,
some garbage collection strategies attempt to separate the short-lived and
long-lived objects into two separate heaps. These two heaps are typically called
the \emph{nursery} and \emph{mature} spaces, as illustrated in
\autoref{fig:nursery-and-mature}. The usual behavior is for objects to be
allocated in the nursery and, if they survive a sufficient number of garbage
collection cycles, to be \emph{tenured} to the mature space. If a large majority
of the objects in the nursery are no longer live at the time the \jre runs a
garbage collection on the nursery heap, then a traversal of the nursery help will
only touch a small number of memory pages. In this way, ignoring the costs of
initialization, reclaiming objects that are short-lived can be very cheap. Some
collectors allow you to specify a separate maxmum size for each, and some let you
specify only the maximum nursery size and the total maximum heap consumption (via
\code{-Xmx}.)
\end{comment}




%% DO WE NEED THIS?
%\paragraph{Concurrent, Parallel, and Real-time Collection}
%\index{Concurrent GC}
%\index{Parallel GC}
%\index{Real-time GC}

\begin{comment}
\section{Building Your Own Lifetime Mechanisms}
\paragraph{The Reference Conundrum}

If you choose to leverage weak and soft references, you are in for a treat of
complex programming. There is a complex programming hassle that stems from
\class{WeakReference} and \class{SoftReference} being normal Java objects. If a
weak reference does not prevent an object from being reclaimable, and the weak
reference itself is represented by a Java object, then what is to keep the
\class{WeakReference} object itself from being reclaimed? The same thing holds
for soft references.

The only way to prevent a weak reference object from being immediately reclaimed
is to reference them, somehow, with strong references. If your goal is to
connect one object with another, via a weak or soft reference, then your job can be
straightforward. The above code, with \code{A.getB()}, works pretty well, as long
as it is properly modified to avoid the race condition. The only room for
improvement is unnecessary carrying around the \class{WeakReference} object
itself for the lifetime of the \class{A} instance, even after the weakly
referenced \class{B} has been reclaimed.

This baggage, of the reference wrappers, runs the risk of being a major
contributor to the overhead of using the weak or soft referencing mechanism. The
cost of a \class{SoftReference} wrapper is typically 12 bytes for the object
header, 4 bytes for the pointer to the referent, and 16 bytes for the clocks
necessary to implement an LRU eviction; it turns out that, to facilitate the
interaction with the JVM, every reference requires an extra 3 pointers, or 12
bytes, on top of these costs. In total, then, every soft reference you use in
your program costs at least 48 bytes. If the \class{A} object consumes only 24
bytes on its own, then softly referencing a \class{B} instance triples the unit
ost of \class{A}. A weak reference wrapper saves those 16 bytes of clocks, and
so costs a still high 32 bytes per wrapper.

The overhead grows even higher when you wish to associate a \class{B}
with an \class{A}, but cannot modify the class definition of \class{A}. In this case, you
must introduce a map in which to store the relation between the two. Worse,
however, is that this construct now leaks memory. When the \class{B} objects are
reclaimed, the map will still hold a strong reference to the reference object
that was serving as a wrapper around that reclaimed \class{B}.

\paragraph{The Basics of Reference Queue Management}
\index{Reference Queues}
\label{sec:reference-queue-basics}

Java provides \emph{reference queues} as a way to avoid this extra baggage, and
to avoid memory leaks in the use of weak and soft references. Using reference
queues adds an extra layer of complexity to an already difficult programming
task, but they are necessary for most uses of weak and soft references. You can
construct a reference wrapper with an associated reference queue. If you do so,
then the associated object, when the \jre decides to clip the weak or soft
reference, will not become immediately reclaimable. Instead, two special things
happen. First, the wrapper will be placed on the associated reference queue.
Second, once the wrapper is on the queue, the wrapper will change its behavior to
no longer reference the referent object. The latter effect complicates the clean
up process: the wrapper is placed on the queue, but calls to \code{get} no longer
return the referent object. 

The reference queue becomes a way for the \jre to notify you that it is ready to
clip the reference.  By associating a reference queue with weak and soft
references, you are given a cleanup hook.
% It is now up to you to finish the job.
With this hook, you can free up resources that are tied to the association that
the weak or soft references has established. For example, you have have native
resources tied to the association, such as open file descriptors. You can also
clean up the memory consumed by the reference objects themselves, such as by
assigning the \code{WeakReference<B> b} field to null in the example above. Since
any calls to \code{get}, from this hook, will return \code{null}, either your
hooks must not require access to the referent object, or you need to secure some
other means of accessing it.

One important task is cleaning up the reference queue itself. If you don't finish
the job properly, then the reference queue will become a source of memory leaks.
In order to detect that an object has been placed on the queue, your only
recourse is to call the \code{poll} method of the associated reference queue.
This will return the reference wrapper that is ready to be clipped, after
removing it from the queue. To avoid a memory leak in the reference queue, you
must call \code{poll} at least at the same rate at which you create reference
wrappers. That is, just before you create a reference wrapper, you must also poll
the reference queue, preferably in a loop, to see if any previously created
wrappers are ready to be clipped. This sounds complicated to get right, and it
is. Be careful!

If you are directly associating an \class{A} with a \class{B}, it is 
necessary to store the reference queue in a static field; storing it in an
instance field of \class{A} wouldn't make any sense. This means that the calls
to poll the reference queue must be protected with critical sections, in order
to avoid race conditions. However, this introduces lock contention problems:
\begin{shortlisting}
class A {
   static ReferenceQueue<B> refQueue;
   SoftReference<B> b;
   
   static void cleanupQueue() {
      synchronized(refQueue) {
         Reference<? extends B> bb;
         while ((bb = queue.poll()) != null) {
            // perform clean up bb
         }
      }
   }
   void makeB(B b) {
      cleanupQueue();   
      this.b = new SoftReference<B>(b, queue);
   }
}
\end{shortlisting}
\autoref{sec:lifetime-management-concurrency-issues} discusses solutions to this
concurrency problem.
\end{comment}

