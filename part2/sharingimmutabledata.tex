\chapter{Sharing Immutable Data}

So far, we have been concerned with representation overhead.
But what about the data itself? If you examine any Java heap, you will
find that a
large amount of the data is duplicated. At one extreme, 
there may be thousands of copies of the same boxed
integers, especially 0 and 1. At the other extreme, there may be many identical
copies of small data structures that have the same shape and data values.
And, of course, duplicate strings are very common.
To save memory, you can share data and data structures, provided that
does not change during an execution. This chapter describes various
opportunities and techniques that you can use for sharing, including a few
low-level mechanisms that Java provides.

\section{Sharing Strings}

It is common for the heap to contain many duplicate strings.
Duplicate string literals, known at compile-time, are shared automatically.
So duplicates in the heap are strings that are created on-the-fly,
during execution. Their values cannot be determined at compile-time, so 
the compiler cannot decide to share them.

For example, for following code, the compiler generates two unique strings,
``Harry'' and ``Tom'', and these strings are stored in \emph{perm
space}, which is a JVM permanent memory area.
\begin{shortlisting}
class BunchOfStrings {
	String name1 = ``Harry'';
	String name2 = ``Tom'';
	String name3 = ``Harry'';
}
\end{shortlisting}

As another example, suppose you are reading in property name-value pairs from 
files into tables:
\begin{shortlisting}
void handleNextEntry() {
	String name = getNextString();
	String value = getNextString();
	propertyMap.put(name, value);
}
\end{shortlisting}
The compiler cannot tell whether any of the strings read are duplicates, even
though the same names and values may be repeated many times among all the files.
%A solution to this problem is to use a 
%sharing pool to avoid creating duplicate strings. 
%A sharing pool is a centralized structure that stores 
%canonical data values that would otherwise be replicated in many objects.
%Before storing a 
%To use a sharing pool, before storing a new
%\class{String}, first check the pool to see if it is already there. If it is,
%reuse it; otherwise, add the new string to the pool. 
%One catch is that if you end up adding many strings to
%the pool that are never reused, then you will waste memory, since the pool
%structure itself has overhead. So you need to have a good idea
%which strings are likely to have duplicate values.
%%As an example, suppose you need to load configuration information from a file,
%%where they are stored as a long list of tables that map property names to
%value. Here is code to read and store a single table entry.
%The names come from a small set
%of 16 distinct names. The values are strings come from
%a set of strings unknown at development time, but a set that is small in size;
%there aren't going to be many distinct values, but you are unwilling or unable
%to nail them down at compile time. How can these maps be stored in a memory
%efficient way?
%Without any special effort, each instance of this kind of configuration map
%would store the some subset of same 16 key strings. Furthermore, each map would
%store duplicates of the values. The following code snippet has those two
%aspects of duplication:
Fortunately, 
 Java provides a built-in mechanism for sharing \class{Strings}, called 
\emph{interning}\index{String interning}, where the JVM maintains a pool of
shared strings. So if you know that the input files will have many duplicates,
you can modify the code as follows:
\begin{shortlisting}
void handleNextEntry() {
	String name = getNextString().intern();
	Object value = getNextString().intern();
	map.put(key, value);
}
\end{shortlisting} 
 This code calls \code{intern} on each newly created string.
If the string has not already been saved, it is added to the internal string
pool, and a pointer to it is returned. Otherwise, the new string is a
duplicate, and a previously saved string is returned.

There are semantic implications of interning
strings that you should be aware of. Under the covers, the JVM is storing unique
string values as sharable objects. But a string consists of two objects,
a \class{String} and a \code{char} array, and it makes a difference which of
these the JVM makes sharable. For example, consider the code: 
\begin{shortlisting}
    String name1 = getNextString();
    String name2 = getNextString();
    System.out.println(name1 == name2);
    System.out.println(name1.equals(name2));
\end{shortlisting}
If \code{name1} and
\code{name2} both store the same string value, then the first print statement
will print \code{false}, and the second print statement will print \code{true}.
This is because  \code{equals} compares the \code{char} arrays of the two
strings, while \code{==} compares the identities. Compare this with code that
interns these strings:
\begin{shortlisting}
    String name1 = getNextString().intern();
    String name2 = getNextString().intern();
    System.out.println(name1 == name2);
    System.out.println(name1.equals(name2));
\end{shortlisting}
In this case,  both print statements
print \code{true}. This is because when you intern strings with the same
value, the \class{String} objects themselves are shared. Therefore, if you are
interning strings, you need to be careful and avoid depending on \code{==} for identity semantics. 
If you want the value of two strings to be
equal \emph{only if} they are the same object, then don't use interning.
If your program just uses \code{equals} for string comparison, you are safe.

 Obviously, there is a cost in doing this, a memory cost, so you shouldn’t 
intern everything, because internally, the JVM is keeping some kind of map, and there is some 
kind of  per entry cost,  so there is a cost, it has to be worth sharing. 
There’s a myth floating around that using this can cause memory leaks, and there actually was a 
version of this Sun’s JVM in 1 or 2 that had a leak, where they were’nt freeing up this memory. 
That’s long been fixed.

It’s implemented in native code, not Java level, in most JVMs.  
The benefit is that hopefully it’s less than having 1,000 copies of the same string. 
So there will be an entry cost of one copy, if you don’t have sufficient sharing, it won’t save. 
 You don’t want to intern all your strings if they aren’t shared. 
 If they are shared to some extent then that savings will …

So you can hit perm space limits. This memory is allocated in JVM’s perm space, 
so if you intern enough stuff, you can get an out of memory of the perm space. 
There is a JVM flag you can set to up the limit of the perm space. I believe that’s the same 
story on IBM, but haven’t been able to verify the details. A few developers told me it is. 


\section{Statics/Enumeration}

example from Nick.

\section{Sharing Scalars}

\section{Wrong data container}
\section{Sharing Strings}

So what they were doing there, was they were saving both a binary version, and an ASCII 
formatted version of the same field, and they were doing that for a lot of fields. 
And since this was a delegated design, this was multiplied everywhere. So it really added up.  
We looked at the field cost, last time, in the actual objects making up the profile, but the 
other thing that is super common is that they were pointing to Strings, actually storing the data, 
and the actual cost of the Strings was pretty high. So the naïve view, especially 
if you are used to languages like C, is that, what’s a couple of characters?  
I’ll just store “Y” or “N”, what’s the big deal of storing one or two characters. 
But as we saw, looking inside the string, the health ratio for something like Y or an N, 
a single character, is 48:1. It takes about 44 bytes to store that string, plus the pointer 
to get there. In some cases these were either constant, or there were things that have just a 
few values. I think it just had three values, where every single record had both an int, or a 
short, and had the pointer to a string, which said Y or N.  This is a super common problem, 
is duplicating data that has a high overhead in its representation. That combination is all over 
the place, and Strings is the big culprit. They had another field like that. It was a policy 
threshold, and it was a constant every single record had this 10\% in it. And
they had the number 10\%, and a pointer to a string “10\%”, and a pointer to a
string, not sharing them. So certainly they would get a huge reduction just by sharing them. 
That’s one approach. It takes a little bit of machinery to build that. You can use String intern 
if you want.  I’ll talk about that. The other thing is just to compute the thing on the fly, 
assuming it’s something relatively easy. Actually these are 2 separate cases.
The 10\% you probably want to either share it or compute it on the fly somehow, because 
that’s probably a number that’s dynamically determined. Something like a Y or an N, 
I would guess is statically determined. That it has a small number of values that you can 
predict at compile time, and in that case you can have some final statics that are determined 
at compile time, and everyone can point to them. Pretty simple.

\section{Sharing Scalars}

Also, recently the boxed scalars, I think this started in 1.5, maybe 1.6, that they have these 
methods called valueOf, where they will do some sharing for you. So if you think you will have 
a lot of copies of a Capital Integer, for example, they won’t share all of them, not like intern,
 where they always share this thing. They allocate a cache at the beginning of very commonly used 
 integers, commonly used across all applications, so it’s not dynamically determined. 
 Somebody at compile time has decided that the numbers from -100 to 100 are likely to be used 
 a lot. So if you happen to hit one of those, you’re going to get a shared one. If you don’t, 
 you’ll get a new Cap Integer or Float, or whatever you are sharing here. So you have to be  
 a little careful using this. You definitely can’t assume that you can use ==. 
 Because sometimes you are going to get objects that are shared, and sometimes you are going to 
 get …  So this is sort of a funny mechanism here.

\section{Pooling Data}


5.6 Redundant Objects

So we see the same pattern at kind of a higher level of not-sharing high overhead data, 
and this was from text analysis system being developed at research. This was a concordance, 
which was the center of an important data structure. This particular problem has been fixed. 
And there were multiple frameworks talking to each other, and one part of it building the 
concordance was relying on another framework to figure out the type of each word was. 
Each word in its context that was being indexed. And so in the concordance, even though the words, 
there were only 20 or 30 types total in this whole vocabulary, this whole classification system, 
there could be hundreds of thousands of these type data structures here, even though there are 
actually only 20 or 30 of them.  So this is the same thing here. Immutable data, that has a 
small number of values, that was highly duplicated, and it turned out the type itself had some 
fields in it, and it delegated its work to String, which of course is highly delegated, 
because it delegates its work to char array. So this was a fairly easy problem to fix by just 
introducing the shared immutable factory pattern to say I need a type object that matches this 
particular constant. If I have one already, then just give me back that otherwise, make a new one 
and put it in your pool, and we’ll share it. The one thing to keep in mind when implementing 
things like that, is to make sure you avoid any lifetime management issues, in particular, 
memory leaks.  You can also introduce a concurrency problem if you are not careful.


You can implement your own map using weak references. Go into tht pattern later. 
To make sure you avoid a memory leak. The downside of that is that there can be some pretty 
high per entry cost. Doing it yourself in Java.  Don’t know the native entry cost, but know 
the per entry in Java is pretty high. 



Common prefix???

5.7 Example: Caching Strings

Most bloated designs have multiple problems, as shown in this example.  (Quiz??)

Analysis of what’s wrong with this example.
So this was an example from one of the Lotus frameworks, from Sametime Gateway, and this 
was one piece of a session connection, and like all the other examples, it’s one piece of a 
data puzzle with other problems and other sources of costs. It was kind of a medium scale run. 
We saw that the biggest part of this data structure had sessions 110 of them. Each of them had 2 
StringBuffers, and that was taking the bulk of the space here.  We looked in to it, and they had 
quite a few different problems. We saw these StringBuffers sitting in the long lived heap, and 
thought, why would anyone store stringbuffers as permanent memory. Typically stringbuffers are 
used as temporaries. They have very aggressive storage allocation, kind of like the collectio
ns, 
with the thought in mind that you are going to grow them. You are going to be editing them.  
Typically, long-lived memory doesn’t have that problem. Typically, Strings in particular, you 
build them up, and then they are pretty stable. So it seems sort of strange. Usually 
StringBuffer
 is 40\% empty space, because it has a doubling algorithm for allocating them.
 The other strange thing was that they had 3 of them per session, and then there was the 
 question of whether they needed them at all. Turns out we looked at the code, and they had a 
 confluence of 3 different issues going on here. First of all, they had a somewhat delegated 
 design, and again, this was one of the consequences that delegated designs can have, where it 
 causes coding pattern to be duplicated. So in this case, for a completely different reason, 
 they had taken their session objects and split them into 3 parts. And they had some good design 
 reasons for doing that for some replication functionality they needed. But along with that, 
 they took a coding pattern that said that everytime they call toString on this thing for some 
 logging purpose, we’re going to save the contents of that String so that we don’t have to 
 recomputed it. That was really their main problem, that they didn’t realize how much space 
 they were 
taking 
up by saving this computation. And sometimes that’s indeed worth it. 
That you compute something and hold onto it.  In this case they realized they didn’t need to hold 
onto that much stuff. So in this case they had 3 problems. One is they were holding onto it, 
and it got multiplied by 3 because it was a delegated design. The second problem was they were 
holding onto it, and they may not need to. The third problem was they were going to hold onto it,
 
StringBuffer was the wrong thing to use.  In the end, they would have been better off 
trimming the StringBuffer, or just calling toString on it, and getting a shorter 
String out of it.




