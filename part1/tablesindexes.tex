I\chapter{Large Collection Structures}
%\chapter{Large Structures for Accessing Data}
\label{chapter:tables-indexes}

In a relational database system, data is neatly organized for you into tables.
While you may suggest a few fields to index, the structures that
allow you to access your data are taken care of for you.  In object-oriented
programming languages you have more freedom. You have a sea of interconnected
objects, and you are responsible for designing the structures that are the entry
points into various groupings of these objects.
In this chapter we look at the memory considerations when
designing large structures for accessing your
data. We'll
look briefly at large collections that just gather data in one place, such as a
list of all the objects of one type. The bulk of the chapter is about
indexes, also known as maps, that let you look up data by value. We'll first look at the costs of large collections,
and at ways to keep them to a minimum for the task at hand. In the second half
of the chapter we'll look at the cost tradeoffs when you need to
design more complex access structures made of multiple levels of collections.  


%Collections, especially large collections, are your
%main tool.
%Maps are the main
%implementation mechanism in these structures \footnote{We use the term map to
%mean a Java collection class, and the term index to describe the general
%functionality.}.

%Large collections, like much else in Java, can
%take up a lot of memory, unless you choose and configure them carefully. 

%, it's easy to create very expensive designs. 


%As we saw in the previous chapter, the
%overhead of different collection choices varies quite a bit. The costs for
%large collections play out somewhat differently than in smaller ones. In
%large collections, whether lists, sets, or maps, the main issue is the
%incremental cost of each new element. This is because the fixed cost of the
%collection is insignificant once the collection is above a certain size.  



%We walk
%through a sample analysis, comparing three alternative designs.


% Here we look at how the costs work out for large collections,
%and what choices are available
%including in open source frameworks if you are able to use these in your
% system.  We'll also look at some
%common special cases. If your requirements fit into one of these cases, there
%are less expensive solutions available. 


%In any large collection, the main
%issue is how to keep down the cost of adding an element. The fixed
%cost of the collection becomes insignificant once the collection is above a
%certain size.  We look at ways to keep these variable costs down: by
%carefully choosing the right collection for the situation; by
%recognizing some special cases that enable some optimizations; and by using
%some of the open source collection classes if they are available to you
%(rephrase all of this is what the reader can do, not as a roadmap).


\section{Large Collections}

Just as with small collections, choosing the right collection for the task
can make a big difference in the memory overhead of large collections.  Suppose
you need to maintain a collection of all the orders processed for the day.  At
the end of the day these orders are posted in bulk to a remote database. The orders
contain their own timestamps, so we don't really care about maintaining the
sequence in which they were received. Figure~\ref{} compares an implementation
using \class{ArrayList} with one using \class{HashSet}. As with small
collections, if we don't need the uniqueness checking or some of the
other features of \class{HashSet}, then we are clearly much better off with \class{ArrayList}.

In larger collections, the variable overhead --- the cost each element incurs
--- determines the cost of the collection. That's because as a collection grows its fixed overhead,
such as wrapper objects and array headers, becomes insignificant. For example,
in an \class{ArrayList} with 100 elements, the fixed cost is only 9\% of the total. With 1000
elements, it falls to 0.1\%.  The difference in size in the above example is
pretty dramatic, more than 7:1.  That reflects the difference in the variable overheads of the two
collection classes. Like much else in Java, variable overheads in large
collections can take up a surprising amount of memory if you are not careful.
%With small collections we need to concern
%ourselves with both fixed and variable costs, for large collections we
%need only look at variable costs. 
As a general rule,
the variable overhead of array-based collections, like \class{ArrayList} is much lower than that of 
entry-based collections where a new entry
object is allocated for each element in the collection. You may have noticed
that most of the collections in the standard collection library are entry-based,
including \class{HashMap}, \class{HashSet}, \class{LinkedList}, and \class{TreeMap}. Table~\ref{} shows a
comparison of variable costs for the most commonly used classes from the standard collections library, 
along with a sampling from open source libraries.


%You may have noticed that in our current example,
%there is a much bigger difference between the two implementations than there
%was in Section~\ref{}, where we compared the same two collection classes in a
%design that had small collections.  For small collections, the fixed costs are
%a larger part of the overhead, whereas here it's only the differences in
%variable costs that matter.  

\paragraph{Excess Capacity}

As we saw in the previous chapter, many collection
classes allocate excess capacity for performance reasons, mainly to accomodate
growth. One difference between small and large collections is the way
excess capacity is computed.  In the very smallest collections, excess capacity
comes from the initial capacity being too large. In contrast, as a collection
grows larger, the amount of spare capacity allocated is proportional to the
number of elements. For example, whenever an \class{ArrayList} needs
more space, it allocates an array that is 50\% larger than its current
size; \class{HashMap} doubles the number of buckets when the number
of elements reaches a user-specified load factor. So for any collection that's
grown beyond its initial size, you can 
think of spare capacity as part of the variable cost.
If an \class{ArrayList} is 1/3 spare capacity, then every
element really costs 6 bytes, rather than the 4 bytes for the array slot that
holds the pointer.

Collections grow in jumps, which makes predicting the size of a collection a
little tricky.  For that reason, Table\ref{} shows
a range of variable costs for each collection.  You can use the minimum
number if you expect no spare capacity. The maximum number gives you a worst
case, if you added just that one extra element that caused the jump.
Slightly less than the midpoint of the range will give you an estimate of the
variable cost if the most recently allocated spare capacity is half occupied.

Solutions for reducing excess capacity for larger collections are the same as
for small collections. If you can estimate the number of elements in advance,
you can try to size the collection carefully when you create it.  If your data structure has a
distinct load phase, and the collection has a \code{trimToFit()} call, you can
trim the size of the collection after the load phase is complete. In hash-based collections, such as
\class{HashMap} and \class{HashSet}, excess capacity is needed to reduce the
likelihood of collisions, so it's important to leave headroom for this
purpose. The default load factor is usually a pretty good guide. 

Excess capacity isn't much of an issue for collections like
\class{HashMap} and \class{HashSet}, where the bulk of the overhead is from the entry objects.
For larger array-based collections, excess capacity can be a more significant
part of the overhead, though it's relative to a more efficient representation in the
first place. 

%Notice that for large collections, the issue of excess capacity is not as
%serious as that for designs with many tiny collections, like those we saw
%in the previous chapter, where the initial 
%capacity is so much larger than the number of elements stored.

\paragraph{Array-based Hash Maps and Hash Sets}

There are two primary ways that hash tables are implemented. Most of the maps and sets
in the standard libraries use a technique known as \emph{chaining} (also
known as open hashing). Figure~\ref{} in the previous chapter shows a typical
implementation. There is a separate entry object for element in the collection.
Each entry object points to a key and a value, and may contain
additional information such as a cached hash code. There is a linked list of
entry objects for each hash bucket.

The other main technique is known as \emph{open addressing} (for added
confusion, it is also known as closed hashing).  In this technique,
keys, values, and other information are stored directly in
arrays. These are usually parallel arrays, though some implementations
use a single array and interleave different kinds of information in
successive slots. Chains of entries that map to the same bucket are threaded through the arrays.
Figure~\ref{} shows a typical implementation. There are many variations in
practice.

Generally speaking, for larger collections, open addressing hash tables use less
memory --- at least in Java, where the cost of an entry object is so high. 
fastutil and Trove are examples of open source frameworks that provide open
addressing maps and sets that save space. The sets in these frameworks
save even more space for a different reason: they are specialized for the task,
rather than delegating their work to a more general map. So unlike in the Java
standard libraries, you are paying only for a value, not a key and value, per
entry.

Since open addressing hash tables usually use less memory, why do so many hash
table libraries use chaining? Generally speaking, hash tables based
on chaining are much simpler to implement. More importantly, there
are performance differences between the two approaches, though there is no easy
rule about one always being faster than the other. For your
own system, if performance of your collections is critical it can be worth doing
some timings first.  Keep in mind that in many systems, the amount of
time spent in hash table lookups is a small fraction of the total execution time to begin with. 

Another thing to be aware of in open addressing implementations is that the
need for excess capacity will reduce the space savings to a greater
extent than in open chaining implementations. So it's important to look at the
entire variable cost when making decisions on which framework to use (see Table
~\ref{}).  For example, fastutil's object to object open addressing
hash map maintains only 9 bytes of data for each element, compared to the standard
\class{HashMap}'s 28. When you add in the greater cost of excess capacity that
difference is reduced to approximately 1:2.  <or example here instead, with absolute numbers>

\paragraph{Sharing the Costs in Entry-based Collections}

Some alternative frameworks provide another approach to reducing space in
entry-based collections. The idea is that your objects become
the collection's entry objects, thus saving a delegation overhead. The downside
is that they transfer some of the work of maintaining the collection to your code.
One example is in the Apache Commons framework, which lets you subclass its map
and map entries. If you have a key with two fields, for example, you would
normally have to wrap those fields into a key object. Now 
you could include those fields in a custom map entry instead, and save a
delegation cost. <figure here?>  This introduces a reliability and maintenance
problem, however, since it relies on subclassing a fairly complex class. You must now make sure
your code doesn't break anything in current and future versions of Commons's
hash map implementation.

A simpler approach is taken by Trove's linked list. If you have a class whose
objects are to be stored in a linked list, your class can implement the
\class{TLinkable} interface. Your class would provide the chaining, and
again, save the cost of a separate entry object.  Some restrictions are
necessary in order for this to work: no instance of your class can
be a member of more than one linked list simultaneously, nor appear more than
once in the same list. In addition, your class must now include
pointer fields, which increase the cost of these instances when they are
not stored in a list.

\section{Identity Maps}
The Java standard library does provide one hash map class that uses an open
addressing implementation. The \class{IdentityMap} class can save you space
if you have the need for a large map that fits its requirements.  The idea is that
it uses the identity of the key object, 
rather than its contents for comparisons. In
other words, it uses \=\= against the key your provide, rather than the \class{.equals()} method.  
This breaks the \class{Map} contract, but there are a number of applications where this doesn't matter.  

Suppose I want to associate additional information with each product.  Using a
standard map, I could map the product's unique key, say SKU, 



\section{Maps with Scalar Keys or Values}

\section{Multikey Maps. Example: Evaluating Three Alternative Designs}

\section{Concurrency and Multilevel Indexes}

\section{Multivalue Maps}

\section{Summary}



