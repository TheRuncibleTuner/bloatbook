\chapter{Reducing Collection Bloat}

 Relationships in an
entity-relationship model are typically implemented in Java using the
standard library collection classes. 
%While a simple 1:1 relationship can be
%implemented with a single map, more complex 1:n, n:1, and m:n are usually 
%implemented with collections inside other
%collections, sometimes nested three or more levels deep. 
It is common for a Java application to create hundreds of
thousands, even millions, of collections, where the vast majority contain only a
very small number of entries.
Our guess is that the
collection class developers would be surprised by this usage pattern. 
Why would they have bothered implementing expandable
structures and clever hashing algorithms for only a few entries?
This mismatch between collection implementation and usage is 
a leading cause of memory bloat. The basic cost of a collection, even an
empty collection, is remarkably high. Creating millions of small collections
multiplies this basic infrastructure cost, which is all overhead, filling the
heap. This chapter shows
 how to mitigate the many-small-collections problem to reduce memory bloat.
 
 \section{Choosing The Right Collection}

The standard Java collections vary widely in terms of memory consumption.
Not surprisingly, the more functionality a collection provides, the more
memory it consumes. Collections range from simple, highly efficient
\class{ArrayLists} to
\class{ConcurrentHashMaps}, which offer sophisticated concurrent access
control at an extremely high price. 
Overly general collections, that provide more functionality than
really needed, is a common pattern leading to excessive memory bloat.
Since collection implementations are hidden, it's
easy to see how this happens.

To illustrate, consider a graph with 100,000 nodes that have four edges each on
average. An obvious implementation is to use a
\class{HashMap}, where the keys are nodes and the values are \class{HashSets}
of edges. For this example, a node is an \class{Integer}, and an edge consists
of two \class{Integers}, a node number and an edge weight.
Figure~\ref{fig:graph-hashset} shows an entity-collection diagram for the graph.
 \begin{figure}
  \centering
 \includegraphics[width=.80\textwidth]{part3/Figures/graph-hashset.pdf}
  \caption{A 100,000-node graph, stored as a
  \class{HashMap} from nodes to \class{HashSets} of edges.}
  \label{fig:graph-hashset}
\end{figure}
%Sun library --  Empty HashSet -- 136 bytes
% 16 bytes HashSet (header + pointer)
% 40 byptes HashMap Object 
% 80 bytes empty array of entries

%HashMapEntry:  24 bytes:  header + 4 fields (value, key, next, hash)
% 4 entries -- 96 bytes
% total overhead for 4 entry hashset: 232 bytes
% 100,000 hashsets with 4 entries is 22.13MB

% HashMap size: 40 for header + 8 for array header
% 24 bytes per entry + 6 per entry in the array (assume extra for growth space)
% so for 100,000 entries, thats 48 + 3,000,000 bytes = 2.86MB
%
% Edge 16*400,000 = 6.4 million = 6.1MB
%
% ArrayList container is 24 bytes (header, size, modcount, pointer) 
% Default array size os 10 -- 10*4+12 = 52 rounds to 56
% ArrayList is 80 (56+24) for 4 entries.
% 400,000 ArrayLists is: 32,000,000 bytes

This is a hugely bloated structure with a bloat factor of 97.5\%.
There are several problems here, that we will address one by one.
 The first problem is that there are 100,000 very small \class{HashSets}
 each consuming 232 bytes, all overhead. It's hard to think of a good reason why
 such a heavy-weight collection should ever be used for storing just four
 entries, and yet, this pattern arises in almost all applications. For small
 sets, \class{ArrayList} is almost always a better choice. \class{HashSet} maintains uniqueness
  and provides fast access, but enforcing uniqueness
is not always needed. If uniqueness is
important, it can be enforced for an \class{ArrayList} 
 with a little extra code, and usually without significant performance loss when
 sets are small. Figure~\ref{fig:graph-arraylist} shows improved memory usage with
\class{ArrayList}. Each \class{ArrayList} incurs 80 bytes of overhead, almost
a third as much as a \class{HashSet}.
 \begin{figure}
  \centering
 \includegraphics[width=.80\textwidth]{part3/Figures/graph-arraylist.pdf}
  \caption{A 100,000-node graph, stored as a
  \class{HashMap} from nodes to \class{ArrayLists} of edges.}
  \label{fig:graph-arraylist}
\end{figure}
This simple change saves almost 15MB, but the bloat factor of 96.7\% is still
quite large. We explain how to reduce this more in later sections.

\section{The Cost Of Collections}
\label{sec:collectioncost}
Let's look at why a \class{HashSet} is so much bigger than an \class{ArrayList}. 
Some of the \class{HashSet} overhead is Java-related and
unavoidable. Other overhead is the result of hard-coded assumptions, for
example, the \class{HashSet} implementation assumes \class{HashSets} will be very large, 
and trades memory space in favor of performance. 
Figure~\ref{fig:hashset} show the causes of unnecessary \class{HashSet} bloat.
 \begin{figure}
  \centering
 \includegraphics[width=.80\textwidth]{part3/Figures/hashset.pdf}
  \caption{The internal structure of a \class{HashSet} showing how
  implementation assumptions waste memory.}
  \label{fig:hashset}
\end{figure}

\paragraph{Reusing HashMap.} Internally, a \class{HashSet} is just a wrapper,
delegating all of its work to a \class{HashMap}.
This decision to reuse the \class{HashMap} code instead of specializing
\class{HashSet} costs an extra 16 bytes, which is reasonable if
\class{HashSets} are big and the fixed overhead costs are amortized away. 
Unfortunately, the fixed cost is magnified when there are many
small \class{HashSets}. 
Also, \class{HashMap} is
more general than needed.
Each \class{HashMap\$Entry} stores a key and a
value, and \class{HashSet} only uses the key, so four bytes are wasted per
entry. Sometimes specialization is a better option than reuse, especially for
library classes, where the usage patterns are not known in advance.
  
\paragraph{Open Chaining.} \class{HashMap} itself is fairly
 expensive. First, the \class{HashMap} object is just a container pointing
 to the actual array of entries. This delegation is necessary in Java.
 Secondly, \class{HashMap} uses an
 open chaining algorithm, which means that clashing entries are chained in a
 linked list. With open chaining, each entry requires its own
 \class{HashMap\$Entry} object and an extra level of indirection.
 
\paragraph{Default Array Size.} 
A \class{HashMap}, which is used to implement a \class{HashSet}, has a default
size of 16 entries, which means that its array of entries has an initial
size of 16. If most \class{HashSets} have only a few entries, this wastes space. 
For example, a \class{HashSet} with five entries wastes 44 bytes.


\paragraph{Bookkeeping Fields.} \class{HashMap} allows callers to iterate over
its set of keys, values, and entries. These sets are cached once
they are created. Every \class{HashMap} has three pointers
to store these sets, which is an extra 12 bytes.
However, its not that common to use
any of these sets, and very rare to use more than one set at a time.
 Certainly when the \class{HashMap} is part of a \class{HashSet}, 
there is never a need for a set of values.
  
 \paragraph{Extra Per-Entry Costs.} Each \class{HashMap\$Entry} stores a
 hashcode, which is an unnecessary redundant field. The most common keys are either
 \class{Strings}, which store their own hashcode, or \class{Integers}, whose
 hashcodes are easy to compute. 
\paragraph{}
An \class{ArrayList} is really just an expandable array, consisting of a
wrapper object and an array of entries, as shown in Figure~\ref{fig:arraylist}.
 \class{ArrayList} is better than \class{HashSet} in two ways. First, it has a
 lower fixed cost, which means that an \class{ArrayList} with just a few
 elements is smaller than a \class{HashSet} with the same elements. Fixed costs
 include wrapper objects and unitialized array elements. The fact that \class{HashSet}
 delegates to \class{HashMap} dramatically inflates its fixed cost. 
 \begin{figure}
  \centering
 \includegraphics[width=.80\textwidth]{part3/Figures/arraylist.pdf}
  \caption{The internal structure of an \class{ArrayList}, which has a
  relatively low fixed overhead, and is scalable.}
  \label{fig:arraylist}
\end{figure}
 Secondly, \class{ArrayList} has a lower per-entry cost, which means that
 \class{ArrayList} scales much better than \class{HashSet}. The per-entry cost
 of an \class{ArrayList} entry is an entry array pointer, which is 4 bytes.
 The per-entry cost of a \class{HashSet} is an entry array pointer plus a
 \class{HashMap\$Entry}, which is 28 bytes. So \class{ArrayList}  is better
 both for small and large sets.

Table~\ref{tab:collection-costs} shows the empty-collection costs of four basic
collections, \class{ArrayList}, \class{LinkedList}, \class{HashMap}, and \class{HashSet}. These costs have been
calculated based on the the Sun JVM and ?? library, using the techniques
described in Chapter~\ref{chapter:delegation}. The various other Java standard
library implementations in circulation have costs
similar to these. You can calculate them using the same methodology.

\begin{table}
  \centering
 %\includegraphics[width=.70\textwidth]{part2/Figures/chapter4/object-overhead.pdf}
 % \includegraphics{eight-char-string}
 \begin{tabular}{llll} \toprule
 	 Collection & Fixed Cost & Per-Entry Cost & Default Size \\ \midrule
 	ArrayList & 80 bytes & 4 bytes & 10 entries \\
 	LinkedList & 48 bytes & 24 bytes & 1 sentinel entry \\
 	HashMap & 120 bytes & 28 bytes & 16 entries \\
 	HashSet & 136 bytes & 28 bytes & 16 entries \\
 	\bottomrule
 \end{tabular}
  \caption{The cost breakdown of four basic Java standard library collections
  with default size and no entries. The fixed cost is for the
   default collection size. The per-entry cost is used to
  determine scalability.}
  \label{tab:collection-costs}
\end{table} 

\section{Properly Sizing Collections}

Collections such as \class{HashMap} and \class{ArrayList} store their entries in
arrays, which grow by reallocation and copying. 
By default, entry arrays are allocated with extra capacity,
to avoid paying these growth costs too often. 
 This is why the initial capacity of an \class{ArrayList} is 10 rather than 2, 
and why its capacity increases by
50\% when it fills up and is reallocated. 
Similarly, the capacity of a \class{HashMap} starts at 16, and grows by a
factor of 2 when the \class{HashMap} becomes 75\% full. Unless you take explicit
action, element arrays are almost always too big.

These default policies trade space
for time, on the assumption that collections grow. However,
typical applications have hundreds of thousands of small collections that
don't grow. As a result, there is no performance gain, and the extra
empty array slots can add up to significant bloat problem.
 
 For \class{ArrayLists}, if you know that there is a maximum
 size $x$ less than the default size of 10, then it's worth passing $x$
 as a parameter to the constructor. This sets the initial capacity of the
 \class{ArrayList} to $x$. However, if you are wrong and an \class{ArrayList}
 grows bigger than $x$, then the \class{ArrayList} will grow by 50\%, which may
 be worse than just taking the default initial size.
 
 Alternatively, you can call the \code{trimToSize} method to shrink the
 entry array by eliminating the extra growth space. Trimming reallocates and
 copies the array, so it is expensive to keep calling \code{trimToSize} while an
 \class{ArrayList} is still growing. Trimming is appropriate after
 it has been fully constructed and will never grow again. In fact, applications
 often have a build phase followed by a used phase. Collections can be trimmed
  between these two phases, so that the cost of reallocation and copying is
  paid only once.
 
 For the graph example in Figure~\ref{fig:graph-arraylist},
 suppose that the the graph is built entirely in one phase, and used in another
 phase, and that all \class{ArrayLists} have the default capacity. There are
 100,000 \class{ArrayLists} with four entries on average, and 400,000
 \class{ArrayLists} with two entries each. Trimming these \class{ArrayLists}
 saves 15.2 million bytes, as shown in Figure~\ref{fig:trimmed-graph}. The
 total size is reduced from ?? to ??, and the bloat factor from 96.7\% to
 95.3\%. This is still rather high, but there are more optimizations ahead.
 % 100,000 * (10-4)*4 = 2,400,000 bytes
 % 400,000 * (10-2)*4 = 12,800,000 byptes
 % total is 15,200,000
 
 \begin{figure}
  \centering
 \includegraphics[width=.80\textwidth]{part3/Figures/trimmed-graph.pdf}
  \caption{The graph example after all of the \class{ArrayLists} have been
  trimmed by calling the \code{trimToSize} method.}
  \label{fig:trimmed-graph}
\end{figure}
 
There is no \code{trimToSize} method for \class{HashSets} and \class{HashMaps},
but it is possible set the initial capacity using a constructor parameter.
  
can also have initial sizes so that they are smaller, but have to ask yourself why you are using HashSets for small sets,
 rather than a less expensive data structure.
 

Talk about LinkedLists\ldots
 The default size initially for an empty collection is 0, so they’re still
 allocating the array with 0 size. Where as the Sun and older JVM’s are always 
 allocating 10 element collection. But on the Harmony classes, the new J9, 
 after you add the first element, they jump it to 12. It’s pretty hard not to 
 get those big jumps in these collection classes. HashMap, the default is 16, 
 and HashSet as well, since it’s based on HashMap. So it’s definitely 
 worth setting the default in these cases where you know you have mostly these 
 small collections. 
 
 Note: Harmony classes have initials size of 0, but then jump it to 12 once the
 first element is added.
 

\section{Avoiding Empty Collections}

A related problem is empty collections, and this is super, super common. 
People are eagerly initializing things, and without realizing that the empty 
collections are pretty costly too. This was the case from JPMorgan 
Chase critsit, that Nick did, and in fact in SessionState, which had all sorts 
of other stuff in it, had these profile objects in it, which were profiles of 
customers, and each of those profiles was a highly delegated design, we saw it 
last week, each one had 40 instances hidden inside that box. 

For those of you who weren’t here last week, this notation is kind of a UML-like 
notation This is a logical data structure and these boxes are hiding other classes.
 The octagonal shaped ones are collections, things implementing relationships. 
 SO profile had quite a few classes inside it, and they all had the same coding 
 pattern in them, where they had these arraylists hanging off of them. 
 In one case it was to track the history of modifications in various fields. 
 In total, each usersession data had 210 empty arraylists hanging off of it, 
 which was rather expensive in this little example here. They were paying  
 8MB in this of just empty arraylists. So what are the remedies here? 
 The simplest thing is to lazily allocate these things. Along with lazy 
 allocation, there’s a nice static method in the collections class, 
called emptyset, where it will return you a pointer to a singleton empty set 
that has all the functionality of a set. EmptySet, EmptyList, EmptyMap, and 
those are great since you can point to them, and the size method will still work,
iterators will still work, all that stuff will still work, and you don’t have 
to allocate an empty collection. The only bad thing with those 2 patterns, 
and you really have to watch out for, is if you give out any references to your 
collections before they’ve been allocated. Because once you give out a 
reference, you expect people to hold on to it, then there’s no way to morph it 
into this other form that’s actually populated. And that’s a serious issue in Java.
 But if you can hide the references within the class, then this is very easy 
 to fix. 

So just a quick look inside the empty collections, you can see that they are not 
all that empty. So all the standard Java collections eagerly allocate their 
subsidiary objects, which means that every empty collection consists of 2 objects, 
2 object headers, a pointer, plus whatever bookkeeping fields they have. 
So you get these rippling effects, you have a really high level code, that’s 
eagerly initializing some package, and it’s eagerly initializing some thing else,
 and eventually it’s initializing some collection, and the collection is doing 
 the same thing; it says, well I’m just going ahead and allocate my array, 
it’s not clear why, it’s either ease of coding, or to avoid an if statement 
check at runtime, it’s not clear. So another area is to see if there’s any 
 performance benefit to this, or is this something that can be changed very 
easily. And juust a quick look at the cost of the empty collections. 
What strikes me – these are the number from both sun and IBM. What strikes
me is that the smallest number here is 48, so there’s certainly no single 
digit anything in Java, but 48 is a pretty high number for something that’s 
empty, if you are going to have a lot of them, and also, there’s a little bit 
of variation, both having to do with whether you’ve made the size default or not, 
and also what kinds of collection class you are choosing.

\section{Fixed Size Collections}

Replacing \class{HashSet} by \class{ArrayList} helps, but it is not the end
of the story. The second problem in Figure~\ref{fig:graph-hashset} is the
implementation of \class{Edge}, which uses an \class{ArrayList} to store the
a target node and an edge label, both \class{Integers}. Even though
\class{ArrayList} is the least expensive collection, its functionality too
general to use for this purposeps6.
 

\section{Replacing Collections With Classes}
