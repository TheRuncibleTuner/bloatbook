
\chapter{Introduction}
\label{chapter:introduction}

Managing your Java program's memory couldn't be easier, or so it would seem.
Java provides you with automatic garbage collection, and a compiler that
responds to your program's operation. There are lots of libraries and frameworks
available, written by experts, that provide powerful functionality. All you have
to do is piece together the parts and let the Java runtime system do the rest
for you.

The reality, unfortunately, is very different.  If you just assemble the parts,
take the defaults, and follow all the good advice to make your program flexible
and maintainable, you will likely find that precious memory resources are wasted
holding on to data that is no longer needed, or even worse, that your system
suffers from memory leaks. All too often, these problems won't show up until
late in the cycle, when the whole system comes together. You may discover, for
example, when your product is about to ship, that your design is far from
fitting into memory, or that it does not support nearly the number of users it
needs to support.  Fixing these problems can take a major effort, requiring
extensive refactoring or rethinking architecural decisions, such as the choice
of frameworks you use.  

Alternatively, a methodology based on sound design can
prevent this type of scenario from happening. Memory usage, like any other
aspect of software, needs to be planned. At its core, programming is an engineering
discipline, and there is no escaping the fact that the consumption of any finite
resource must be measured and managed.


\section{A Short Quiz}

 To start you thinking about memory
consumption, here is a quiz to test how good you are at estimating sizes of Java objects. 
(Assume a 32-bit JVM.) If you look inside a typical Java heap, it is mostly filled with the kinds of
objects used in the quiz --- boxed scalars, strings, and collections.
\begin{verbatim}

   What is the size ratio in bytes Integer to int?
   
      a. 1:1
      b. 1.33:1
      c. 2:1
      d. 4:1
      e. 8:1
      
\end{verbatim}
Correct answer: d. 

 Every time
a program instantiates a class, there is an object created in the heap, and as
shown by the 4:1 size ratio of \class{Integer} to \class{int}, objects are not
cheap.
\begin{verbatim}
   
   How many bytes in an 8-character string?

      a. 8 bytes
      b. 16 bytes
      c. 20 bytes
      d. 40 bytes
      e. 56 bytes

\end{verbatim}
Correct answer: e.

Strings often consume half of the heap and are
surprisingly costly. If you are a C programmer, you might think that an 8-character string should consume 9 bytes
of memory, 8 bytes for characters and 1 byte to indicate the end of the string.
What could possibly be taking up 56 bytes? Part of the cost is because Java uses
th 16-bit Unicode character set, but this accounts for only 16 of the 56 bytes.
The rest is various kinds of overhead.
\begin{verbatim}             
   Arrange the following 2-element collections in size order:
    
      ArrayList, HashSet, LinkedList, HashMap
      
\end{verbatim}
Correct answer: ArrayList, LinkedList, HashMap, HashSet.
  
After strings,
collections are the most common types of objects in the heap. Surprisingly, a
\class{HashSet} is bigger than a \class{HashMap} --- an interesting fact that
will be explained later.
\begin{verbatim}      
   How many collections are there in a typical heap?
   
      a. between five and ten
      b. tens
      c. hundreds
      d. thousands
      e. one or more orders of magnitude bigger than above
      
\end{verbatim}
Correct answer: e.
 
In typical real programs, having 100's of thousands and
even millions of collection instances in a heap is not at all unusual. If there are a million collections in
the heap, then the collection choice matters. One collection type might use 20
bytes more than another, which may seem insignificant, but in a production
execution, the wrong choice can add close to 20 megabytes.
\begin{verbatim}
   What is the size of an empty ConcurrentHashMap?
   
      a. 17 bytes
      b. 170 bytes
      c. 1700 bytes
      d. 17000 bytes
      e. 500 bytes
                 
\end{verbatim}
Correct answer: c.
 
\class{ConcurrentHashMap}, compared to the more common
collections in the standard library, is surprisingly expensive. If you are used to creating
hundreds of \class{HashMaps}, then you might think that it is not a problem to
create hundreds of \class{ConcurrentHashMaps}. There is certainly nothing in
the API to warn you that \class{HashMaps} and \class{ConcurrentHashMaps} are
completely different when it comes to memory usage. This example shows why
understanding memory costs are important.

The quiz gives some sense of how surprising the sizes are for the Java basic
objects, like \class{Integers}, strings, and collections. When code is layered
with multiple abstractions, memory costs become more and more difficult to
predict.

\section{Facts and Fictions}

In addition to the technical and engineering challenges that managing memory
pose, there are other reasons why memory problems are so common. In particular,
the software culture and popular beliefs can lead you to ignore memory costs. 
Some of these beliefs are really myths --- they might have once been true, but
no longer.  Here are several.

\callout{myth1}{Memory Is Cheap.}{
Since memory is so cheap, you
do not have to think of memory as a finite resource.  In fact, to avoid code
complexity, you should not even think about how much memory is being used.
}

There is a wide-spread belief that objects are free, at least temporaries are,
and everything will be taken care of for you by the garbage collector.
Given all of the research on garbage collection and runtime optimization, this
is not a surprising perception. Therefore, much of software engineering focuses on
design from a maintainability standpoint, and assumes the performance will
magically be taken care of.

In fact, all of the commercial JITs that
we know of are doing absolutely nothing in terms of storage optimization, so
that every single object, with all of its fields, ends up as an object in the
heap, taking up space.  We'll look into the details of what that means.
Yes, garbage collectors clean up temporary objects, but there are many
objects that are not temporaries and therefore not garbage-collected. It is the
long-lived objects that cause memory problems.


\callout{myth2}{Libraries and Frameworks are Optimized.}
{Another common myth is that the libraries frameworks are already optimized,
because these were written by experts.
} 

Standard libraries and frameworks are usually optimized for speed, not
necessarily memory usage. Even when framework authors try to pay attention to
memory, they often have a hard time predicting what the usage of their
framework is going to be. Sometimes they guess wrong, sometimes they don't know
where to start.  So it's very unlikely that a framework has been optimized for
your particular use case.  And of course, the nesting of frameworks results in
layers of unoptimized memory costs.

\callout{myth3}{Nothing Can Be Done.}
{Java is expensive, and there is nothing you can do about it.
This is just the cost of object-oriented programming in Java.
}

The whole purpsoe of this book is to show that there are informed trade-offs and
many techniques that a programmer can employ to improve memory usage. There is
almost always something you can do!

\callout{myth4}{Improving Memory Usage Hurts Performance.}
{There will always be a performance/memory tradeoff. If you improve memory
usage, then the application will run slower. 
Similarly, if you improve performance, the memory usage will suffer.
} 

This is a false dichotomy in a lot of people's minds: if an application is
using a lot of memory, then it must be buying you something in terms of performance. 
But in reality, that is not always the case. In fact, sometimes bad memory usage will
result in poor performance as well. For example, if 
the heap is holding on to a lot of long-lived objects, then there is very little
headroom for temporaries, and so the garbage collector has to run much more
often.  Similarly, if there are too many long-lived objects, then your cache may
be too small for optimal performance.

\callout{myth5}{There are No Memory Leaks in Java.}
{Since Java has a garbage collector, it isn't possible
to have a memory leak in Java.
}

Java is often referred to as having a managed runtime. An important
part of this is automatic garbage collection. The standard sales pitch
here claims that manual reclamation of memory isn't required, and, for
the most part, this is actually true. Memory leaks occur frequently in
languages like C++, where the programmer can easily forget to free an
object when the variable pointing to it goes away.  However, in Java, the
garbage collector automatically finds free objects when pointer variables go
away. So how can you get a memory leak? 

Problems arise when long-lived data
structures hold on to objects too long, and these structures continue to grow
indefinitely. The garbage collector cannot collect objects that are still part
of live structures. If structures continue to grow without bound, eventually you
will run out of memory. This is, in fact, a memory leak, and can be a
particularly hard problem to solve. Managing the lifetime of objects and data
structures is part of any good memory model design. The second part of this book
deals extensively with this topic.

\section{\thetitle}

%[NOTE(GSS): this is our approach, with a roadmap of the book.
%Needs to be rewritten/restructured to reflect our current breakdown: space,
%lifetime, scalability.]

%[NOTE(GSS): Somewhere in here will be a description of bloat factor and of E-C
%diagrams.  Just a high-level description of each in the Intro, detailed
%descriptions and examples are in Chapter 2.]

Central to good design is a keen focus on understanding your requirements.
In the context of memory consumption, there are important aspects of your needs
to keep in mind. Do you need random access into this data? Will entries ever be
deleted from collections? Does this entry need to remain alive for the duration
of the program? Which collections will grow larger as various aspects of load
increase? The book will guide you through these design requirement questions,
with a constant focus on common patterns that come up in practice. It shows you
how to recognize these patterns in your designs, and give you relevant
information about costs and other pitfalls.

Throughout the course of this book, you will learn three skills, to aid you in
designing more efficient data models:
\begin{enumerate}
  \item Estimating memory efficiency with simple back-of-the-envelope
  calculations.
  \item Recognizing common patterns of memory usage.
  \item Using the mechanisms that Java provides in order to properly manage the
  lifetime of your objects, thus avoiding memory leaks, and manage data models
  that do not fit into the Java heap.
\end{enumerate} 

% probably overkill:
%\dividingline

%\subsection{Estimating the Efficiency of Your Design}
%discuss estimating (Edith text on counting bytes, etc is great) (including
%   scalability discussion) (and focusing on important stuff)
%discuss health very briefly
%discuss entities and collections

\autoref{part:1} presents the issues of estimating memory efficiency.
\autoref{chapter:memory-health} shows you how to compute an accounting metric,
the \textbf{Bloat Factor}, which measures the density of actual data in your
data models. Memory spent on pointers, and on headers that the Java runtime
tacks on to every object, are not absolutely necessary parts of a design. Poor
designs will waste more space on these overheads, and thus have a high bloat
factor. If you read only one chapter of this book,
\autoref{chapter:memory-health} is the one to focus on.

\autoref{chapter:memory-health} also introduces a diagramming technique, the
\textbf{Entity-Collection Diagram}, that aids in determining these costs, and in
comparing the amount of bloat in design alternatives.
An E-C Diagram makes explicit the two key aspects of the health of a design:
% highlights the major elements of the data model implementation, so that the
% costs and scaling consequences of the design are easily visible.
% These diagrams appear throughout the book to illustrate various implementation
% options and their costs.
the implementations of the \emph{entities} of your application, such as your
business objects, and way you have chosen to associate them using collections.
% The kinds of choices you make to improve the storage of your entities are
% often different from those Collections are also depicted as nodes, using an
% octagonal shape.
This is different from UML class diagrams, where associations are shown as
edges.
\autoref{chapter:delegation} through
% \autoref{chapter:field-patterns},\autoref{chapter:representing-values},
\autoref{chapter:sharing-immutable-data} cover issues related to the design of
entities.
\autoref{chapter:brief-introduction-collections} through
% \autoref{chapter:representing-relationships},
% \autoref{chapter:tables-indexes},
\autoref{chapter:dynamic-records} help with planning out to use off-the-shelf
collections, and also with the design of new collections libraries.

% discuss looking at each data structures separately [NMM ??]

\begin{comment}
[NMM 20120628 too much E-C diagram detail for intro?]
A data model implementation begins with a conceptual understanding of the
entities and relationships in the model.  This may be an informal understanding,
or it may be formalized in a diagram such as an E-R diagram or a UML class
diagram.  At some point that conceptual model is turned into Java classes that
represent the entities, attributes, and assocations of the model, as well as any
auxiliary structures, such as indexes, needed to access the data.  The example
below shows a simple conceptual model, using a UML class diagram.  A Java
implementation of that model is also shown, using rectangles for classes and
arrows for references.  %The Java diagram below is typical of a schema diagram,
in that it shows
\end{comment}

% probably overkill:
%\dividingline

\autoref{part:2} discusses managing the lifetime of objects. In
\autoref{chapter:lifetime-requirements}, you will learn how to establish the
lifetime requirements of your data, by mapping your needs to one of four common
lifetime patterns: temporaries, permanently resident objects, objects with
correlated lifetimes, and objects that represent a time-space trade-off.
\autoref{chapter:lifetime-fundamentals} provides a primer on the memory
management facilities that Java offers.
\autoref{chapter:lifetime-implementation-strategies} and
\autoref{chapter:trading-space-for-time} focus on the last two of these lifetime
patterns.

% probably overkill:
%\dividingline

In addition to determining the bloat factor of individual data structures and
avoiding memory leaks, it is important to estimate how well the overall design
will scale up as load increases. The final part of this book, \autoref{part:3},
covers issues related to the scalability of your designs.
\autoref{chapter:estimating-scalability} teaches you strategies for estimating
the scalability of a design, given an E-C Diagram.
\autoref{chapter:large-long-lived} covers the cases when your data model still
does not fit, even after applying the tuning methodology of \autoref{part:1}.
Sometimes you need to tear down the elements of the facade of object
orientation, and this is entirely possible while remaining largely within the
confines of Java, and without resorting to the use of secondary storage.
Finally, \autoref{chapter:secondary-stores} gives strategies for the case when
you must resort to the use of disk or remote storage in order to make your data
fit.




\begin{comment}
\section{Conventions Used in This Book}

[NOTE(GSS): add data structure to the list.  possibly add relationship as well.]

Terms like object can have different meanings in the literature.  The following are the conventions used throughout this book.

\begin{itemize}
\item A \textit{class} is a Java class. A class name, for example \texttt{String}, always appears in type-writer font. 
\item A \textit{data model} is a set of classes that represents one or more logical concepts.
\item Finally, an \textit{object} is an instance of a class, that exists at runtime occupying a contiguous section of memory.
\end{itemize} 
\end{comment}





\begin{comment}
 % NICK's NOTES
microscopic estimating (field-level counting), and accounting to predict
scale

EC diagram, bloat factory, scaling, 

lifetime: sometimes it's not a leak, just a consumption problem (in-memory
design, didn't fit)

sometimes optimizations cost: making a side object for rarely used fields; when
is it useful sharing immutable data (how much sharing before factoring it out
is worthwhile)

what java gives you, what it doesn't, some things are kinda hard to use; java
makes it hard for you

you actually have control



preface

things are hard to change at some point. it's easy to get to an irreconciliable
spot.

intro

why isn't this just for systems programmers making b-trees? this is about
everyday application development

i have GC, why care about lifetime?
i have standard data structures, why care about data model design?

data modeL: entites and relations

visual presentation of density
[flyweight: canonicalizing map]
\end{comment}