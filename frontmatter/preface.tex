\chapter*{Preface}
\label{chapter:preface}

Excessive memory consumption is a chronic problem in Java applications.
Over the past dozen years, we have helped developers, testers, architects, and
performance analysts get to the root of their memory inefficiencies.
This is a persistent problem, and cuts across the gamut of applications.
Client, server, and batch applications --- none of them seem to be immune. They
commonly suffer from memory exhaustion due to memory leaks, or due to
insufficient memory capacity to handle their needs.

These failures continue to occur, despite the steady march of available memory.
Ten years ago, a 500MB heap was considered big. For a while, as load and added
features increased demand for memory, it was sufficient to throw hardware at the
problem. At least, this was true, ignoring memory leaks.
Now, as memory requirements grow into the multi-gigabyte range, teams turn to
64-bit architectures and distributed in-memory stores, in order to leverage even
larger heaps.

%Faced with the black box that is the Java heap, they are forced to
%accept often unpallateable solutions: either limit functionality to that which
%\emph{can} fit, or spend large amounts of money buying more hardware.



% During the many years we have spent studying the performance of Java
% applications, it has become clear to us that the problems related to memory is
% a topic worthy of a book.

%Computers are now equipped with gigabytes of memory, yet these teams often find
%their applications on the brink of exhausting available resources. 

Increasing memory capacity is a perfectly fine solution, but there are
alternatives that offer large reductions in memory consumption, at the expense
of some extra design work up front. Even though the potential gains are there,
most developers treat the Java heap as a black box.
Java programmers are encouraged not to think about physical storage, and instead
to let the runtime worry about it. They code according to the constraints of
budgets and best practices. What pops out the other end, when an application is
run for the first time, is seen as largely unpredictible, some unknowable
function of the engineering and architectural choices the team has made.

This is a reasonable position to take, because much of the heap is hidden from
view. Programming has become an act of assembling reusable libraries and
frameworks. Developers are routinely faced with ``icebergs''. They code to APIs
which create a mountain of objects under the covers.

That is the subject of this book: opening up this mystery, and presenting the
possibility of practical memory-conscious programming in Java.

There is great room for improvement because Java heaps are not just big, but
filled with bloat. The bytes in every application's heap can be divided into two
parts. Some of the heap is ``real data'', the names of employees, their
identification numbers and age. The rest is, in various forms, the overhead of
storing this data. The ratio of these two numbers gives a good sense of the
memory efficiency of the implementation. A bloated heap has a high ratio of
overhead to real data.

In our experiences, we have seen ratios as high as 19:1, where as much as 95\%
of memory devoted to overhead. It is typical to see 50-60\% overhead: less than
half the heap is storing real data!
% This much bloat is an indication that a lot of memory is being used to
% accomplish little.
This level of overhead often impacts the scalability of the application. We have
seen an application where a simple transaction needs 500 kilobytes for the
session state for one user. This figure is the slope of the curve that governs
the number of simultaneous users the system can support.


\begin{comment}
By the time we are called in to help with a performance problem, the situation
is often critical. The application is either in the final stages of testing or
about to be deployed. Fixing problems this late in the cycle is very expensive,
and can sometimes require major code refactoring. It would certainly be better
if it were possible to deal with memory issues earlier on, during development or
even design.

Why ...? %Framework designers have an especially hard problem in addition, of
trying to predict their usage, and design for every possible case, often an
impossible task, usually leading to waste for some case that matters to you!
While there is much good advice on how to code flexible and maintainable
systems, there is little information available on space. The space costs of
basic Java features and higher-level frameworks can be difficult to ascertain.
In part this is by design - the Java programmer has been encouraged not to think
about physical storage, and instead to let the runtime worry about it. The lack
of awareness of space costs, even among many experienced developers, was a key
motivation for writing this book. By raising awareness of the costs of common
programming idioms, we aim to help developers make informed tradeoffs, and to
make them earlier.

The design of the Java language and standard libraries can also make it more
difficult for programmers to use space efficiently.  Java's data modeling
features and managed runtime give developers fewer options than a language like
C++, that allows more direct control over storage. Taking these features out of
the hands of developers has been a huge plus for ease of learning and for safety
of the language. However, it leaves the developer who wants to engineer frugally
with fewer options. %more important to make these choices carefully Helping
developers make informed decisions between competing options was another aim for
the book.


%lifetime management. awareness of mechanisms & importance of understanding mechanisms.


%Compared to systems languages like C, Java space costs are high, even for the most basic building blocks. This makes it all the more important for developers to be aware of memory costs.  Java heaps are not just big, but are often bloated, with as much as 80\% of memory devoted to overhead. Memory bloat can have a serious impact on development schedules and on the scalability of deployed systems. Fortunately, bloated designs are not an inevitable consequence of object-oriented development.
\end{comment}

This book addresses three aspects of using memory well:
\begin{enumerate}
	\item \textbf{Representing your data efficiently}. The book illustrates
	common modeling patterns, shows you how to estimate their costs, and
	discusses tradeoffs that can be made.
	\item \textbf{Avoiding memory leaks by managing object lifetimes}, from very
	short-lived temporaries to longer-lived structures such as caches.
	\item \textbf{Estimating the scalability of your designs}, by identifying the
	extent to which bloat governs the amount of load you can support.
\end{enumerate}
%Lifetime management issues are a common source of bugs, such as memory leaks,
%and inefficiency.
Throughout the book we use examples to illustrate common
idioms. Most of the examples are distilled from cases we have
seen in deployed applications. Some of them may seem silly at first, but, over
the top as they may seem, they truly represent the norm. 
%Many of them occur in
%the standard library itself, a piece of code one would think would be highly
%optimized, given its prolific use. 
In addition to presenting an approach to better design, this book also serves as
a guide to Java memory management mechanisms. These include features in the
language proper, as well as the garbage collector and the standard libraries. 

\begin{comment}
While the book is a collection of advice on practical topics, it is also
organized so as to give a systematic approach to memory issues. When read as a
whole it can be helpful in seeing the range of topics that need to be
considered, especially early in design. That does not mean that one must read
the whole book in order, or do a comprehensive analysis of every data structure
in your design, in order to get the benefit. The chapters are written to stand
on their own where possible, so that if a particular pattern comes up in your
code you can quickly get some ideas on costs and alternatives. At the same time,
familiarizing yourself with a few concepts in the Introduction will make the
reading much easier.
\end{comment}



% This book is a practical, systematic, and comprehensive guide to
% memory-conscious programming in Java. It walks though numerous examples taken
% from real applications, illustrating common design problems that lead to
% memory bloat, and looks inside the Java collection classes and runtime. It
% details a methodology for programmers to follow. Our aim is to empower
% developers to avoid pitfalls, make informed tradeoffs, and to show how
% dramatic improvements in memory efficiency are sometimes possible with a
% little care.

The most important part of this teaching is to apply it early.
Fixing data modeling problems late in the development cycle is usually
impossible. By that time, APIs and storage schemas have been fixed.

The book is appropriate for a wide range of Java developers and architects,
those practitioners involved with framework and applications developers, who are
faced with decisions every day that will have impact down the line in system test and production.
It is also aimed at technical managers and testers, who need to make sure that
Java software meets its performance requirements.  This material should be of
interest to students and teachers of software engineering, who would like to
gain a better understanding of memory usage patterns in real-world Java
applications. Basic knowledge of Java is assumed.

\begin{comment}
Much of the content relies on knowing or measuring the size of objects at
runtime. Sizes vary depending which JRE you are using. Our reference JRE is Sun
\javasix Update 14. Unless otherwise stated, all sizes are for this reference
JRE. The book is self-contained in that it teaches how to calculate object sizes
from scratch. We realize, of course, that this can be a tedious endevour, and so
the appendix provides a list of tools and resources that can help with memory
analysis. Nevertheless, we belief that performing detailed calculations are
pedagogically important.

[NOTE(GSS): Roadmap could be in Intro, possibly interwoven with approach.]

The book is divided into four parts:

Part 1 introduces an important theme that runs through the book: the health of a
data design is the fraction of memory devoted to actual data vs. various kinds
of infrastructure. In addition to size, memory health can be helpful for gauging
the appropriateness of a design choice, and for comparing alternatives. It can
also be a powerful tool for recognizing scaling problems early.

Part 2 covers the choices developers face when creating their physical data
models, such as whether to delegate data to separate classes, whether to
introduce subclasses, and how to represent sparse data and relationships. These
choices are looked at from a memory cost perspective. This section also covers
how the JVM manages objects and its cost implications for different designs.
  
Part 3 is devoted to collections. Collection choices are at the heart of the
ability of large data structures to scale. This section covers, through
examples, various design choices that can be made based on data usage patterns
(e.g. load vs. access), properties of the data (e.g. sparseness, degree of
fan-out), context (e.g. nested structures) and constraints (e.g. uniqueness). 
We look closely at the Java collection classes, their cost in different
situations, and some of their undocumented assumptions. We also look at some
alternatives to the Java collection classes.
 
Part 4 covers the topic of lifetime management, a common source of inefficiency,
as well as bugs. This section examines the costs of both short-lived temporaries
and long-lived structures, such as caches and pools.  We explain the Java
mechanisms available for managing object lifetime, such as ThreadLocal storage,
weak and soft references, and the basic workings of the garbage collector.
Finally, we present techniques for avoiding common errors such as memory leaks
and drag. %plus making things fit.

\end{comment}