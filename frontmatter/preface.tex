\chapter*{Preface}
\label{chapter:preface}

For over a decade, we have helped developers, testers, and performance
analysts with memory-related problems in large Java applications.  
We have discovered that, in spite of the fact that computers are now equipped
with gigabytes of memory, Java developers face an uphill battle getting their applications to fit
in memory. Fifteen years ago, a 500MB heap was considered big.  Now it is not
unusual to see applications that are having trouble fitting into 2 to 3
gigabyte heaps, and developers are turning to 64-bit architectures to be able to
run with even larger heaps.

By the time we are called in to help with a memory problem, the situation
is often critical. The application is either in the final stages of testing or
about to be deployed. Fixing memory problems this late in the development cycle
is often very costly, and may require major code refactoring. It is clearly much
better to anticipate memory requirements in the design phase, but this is rarely
done. This observation is the motivation for this book. While there has
been much written on how to build systems that are bug-free, easy to maintain, and secure, there is
little guidance available on how to use Java memory efficiently and correctly.

This book presents practical techniques and a comprehensive approach to making
informed choices. It covers best practices and traps, and addresses three distinct aspects of using memory
well:
\begin{enumerate}
	\item \textbf{Representing data efficiently}. The book illustrates
	common modeling patterns, shows how to estimate their costs, and
	discusses tradeoffs that can be made.
	\item \textbf{Managing object lifetimes}, from very
	short-lived temporaries to longer-lived structures such as caches, and
	especially, avoiding memory leaks.
	\item \textbf{Estimating the scalability of designs}, by identifying the
	extent to which memory overhead governs the amount of load that can be
	supported.
\end{enumerate}

Java developers face some
unique challenges when it comes to memory.
First, memory usage is hidden from developers, who are
encouraged to treat the Java heap as a black box, and instead to let the runtime manage it. 
When an
application is run for the first time, the size of the heap is largely
unpredictible, some unknowable function of the engineering and architectural choices the team has made.
A Java developer, assembling a system out of reusable libraries and frameworks,
is truly faced with an ``iceberg'', where a single API call or constructor may
involve many layers of hidden framework code. We have seen over and over again
how easy it is for space costs to pile up across these layers.

Secondly, Java heaps
are not just big, but filled with bloat. The bytes in every application's heap can be divided into two
parts. Some of the heap is ``real data'', such as the names of employees, their
identification numbers and their ages. The rest is, in various forms, the
overhead of storing this data. The ratio of these two numbers gives a good sense of the
memory efficiency of the implementation. A bloated heap has a high ratio of
overhead to real data.

In our experience, we have seen ratios as high as 19:1, where as much as 95\%
of memory is devoted to overhead. In other words,
way less than half the heap is storing real data! This level of overhead often
impacts the scalability of the application. And this doesn't include duplicate
data and data that is not really needed. For example, in one application, a
simple transaction needed 500 kilobytes for the session state for one user. This
figure is the slope of the curve that governs the number of simultaneous users the system can support.  

The design of the Java language and standard libraries contribute to high
overhead ratios. Java's data modeling features and managed runtime give
developers fewer options than languages like C++, that allow more direct control over
storage. Taking these features out of the hands of developers has been a huge
plus for ease of learning and for safety of the language. However, it leaves the
developer who wants to engineer frugally with fewer options. 

The good news is that it is possible to make intelligent choices that save
memory with existing Java building blocks --- there is no need to avoid good
coding practices nor rewrite libraries. However, you do need to understand how
to estimate the cost of various options and more consciously engineer the
lifetime of objects. Through the extensive use of examples, this book guides you
through common memory usage patterns. For each pattern, we help you understand
what it costs, and how to choose among alternative solutions. We also help you
focus your efforts where it matters the most.

The examples are chosen to illustrate common idioms, with the expectation that
the reader will be able to carry the ideas presented into other situations
(such as evaluating library classes we haven't discussed). As far-fetched as
some of the examples may seem, most of them are distilled from cases we have seen 
in deployed applications. As in other domains, truth can be stranger than
fiction.

The content is appropriate for a wide range of Java practitioners, and only
basic knowledge of Java is assumed.
Practitioners involved with either framework or application development can
take this knowledge to produce more efficient applications and ones that are less prone to memory leaks.
Technical managers and testers can benefit from the knowledge of how memory
consumption scales up, as they help the team sanity check its designs in larger
scale environments. This material should be of interest to students and teachers
of software engineering, as it offers insight into the challenges of engineering 
at scale.

