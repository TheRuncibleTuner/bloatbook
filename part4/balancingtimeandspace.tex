%correlated with need: saving space
%deferred deletion: saving time

%sometimes we extend lifetime to optimize (for time)
%sometimes we shorten lifetime to optimize (for space)



\chapter{Time-space Tradeoffs}
\index{Time-space Tradeoffs}
\label{chapter:time-space-tradeoffs}

Typically, objects die soon after the point in time of their last use, once all
dominating references are removed or naturally go out of scope. Without any
optimizations, objects live and die according to this \emph{natural lifetime}
that was discussed in \autoref{sec:natural-lifetime}. Sometimes it is beneficial
to extend, or shorten, the natural lifetime of an object. For example, if every
request creates an object of the same type, with the same, or very similar,
fields, then you should consider caching or pooling a single instance of this
object. There are four important cases of time-space tradeoffs. The first covers
the situation where recomputing attributes, rather than storing them, is a better
choice. The next three cover situations where spending memory to extend the
lifetime of certain objects saves sufficient time to be worthwhile: caches,
sharing pools, and resource pools.


%Up till now, the lifetime requirements of objects have been treated as a hard
%truth. Every object has a \emph{natural} lifetime.
%The objects that are correlated with a program phase should naturally die when
%the phase ends. Unless, that is, there is some profit in having it live longer.

%\callout{def:naturallifetime}{The Natural Lifetime of Objects}{
%The \emph{Natural Lifetime} of an object is the duration of time governed by
%its first and last use, in the absence of any optimizations.}

%This chapter discusses when it is profitable, either in terms of time or space,
%to extend or shorten the natural lifetime of an objects. 

\section{Computed versus Stored Attributes}
\index{Computed versus Stored Attributes}
If the data stored in an object is cheap to recompute or refetch from an
external data source, then a good policy would be to treat the object as a
temporary. Performing a few dozen machine instructions is very likely to be a
worthwhile tradeoff, if memory consumption is the limiting resource for
scaling up\index{Scaling Up}. 


\section{Caches}
\label{sec:caches}
\index{Caches}

\marginpar{A \textbf{Cache} is a map that holds expensive data values, each
accessed by a unique key.}
You do have to be careful, though. Recall our earlier example that creates a new
instance of the date parser \class{DateFormat} for each iteration of a
loop. Here, as is quite common, something expensive to compute, that
\class{DateFormat}, is treated as a temporary. If the data stored in an
object is expensive to recompute or refetch, and there is some chance it might
be used in the future, then it is worthwhile to keep it around.

\index{Time-Space Tradeoffs}
Finding the right balance of time and space is the goal of a good cache
implementation. The expense of re-fetching data from external data sources and
recomputing the in-memory structure can often be amortized, at the expense of
stretching the lifetime of these data structures. By increasing the actual
lifetime on an object you will very likely increase peak memory consumption. A
good cache defers the time that an object will be reclaimed, as long as there is
sufficient space to handle the flux of temporary objects your application
creates. It holds on to a data structure after the current operation is finished
with it, in the hope that other operations in the near future will reuse it.

\section{Sharing Pools}
\label{sec:sharing-pools}
\index{Sharing Pool}

\marginpar{A \textbf{Sharing Pool} stores canonical instances of data
values that would otherwise be replicated in many objects.}
A cache amortizes the time cost of fetching or initializing data. An orthogonal
issue lies in the memory expense of storing many copies of the same data
throughout the heap. This is especially a problem with strings. Heaps can often
store the same string a dozen times.

\begin{example}{Duplicate Strings}
You application loads data from a file. This data contains a large number of
name-value maps that will be used frequently throughout program execution.
These maps represent configuration information. The names come from a small set
of 16 distinct names. The values are strings come from
a set of strings unknown at development time, but a set that is small in size;
there aren't going to be many distinct values, but you are unwilling or unable
to nail them down at compile time. How can these maps be stored in a memory
efficient way?
\end{example}

Without any special effort, each instance of this kind of configuration map
would store the some subset of same 16 key strings. Furthermore, each map would
store duplicates of the values. The following code snippet has those two
aspects of duplication:

\begin{shortlisting}
void handleNextEntry() {
	String key = getNextString();
	Object value = getNextString();
	map.put(key, value);
}
\end{shortlisting} 

Java provides a built-in mechanism for sharing the contents of strings across
many string instances. By \emph{interning}\index{String interning} a Java
\class{String}, you ensure that the returned \class{String} will only have
distinct storage if it is a string value that hasn't been interned yet. You can
modify the first try as follows:

\begin{shortlisting}
void handleNextEntry() {
	String key = getNextString().intern();
	Object value = getNextString().intern();
	map.put(key, value);
}
\end{shortlisting} 

It is possible to do even better, if you have the luxury of modifying both ends
of the communication channel, i.e. both the serialization and this
deserialization code. There are only 16 distinct names used in all instances of
this configuration map. This seems like a perfect case for an enumerated type.
An enumerated type can be used to represent strings as numbers at runtime. The
only place the strings are stored is in the string constant pool\index{Java's
Constant Pools}. Each class, when compiled, keeps a pool of the strings that
are used by code in that class. In this way, an enumerated type is an even more
highly optimized sharing pool than that provided by the interning mechanism:

\begin{shortlisting}
enum PropertyName = {...};
void handleNextEntry() {
	PropertyName key = getNextPropertyName();
	Object value = getNextString().intern();
	map.put(key, value);
}
\end{shortlisting} 

There is an important variant of a sharing pool called the Bulk Sharing Pool.
Like a normal sharing pool, the goal of a bulk sharing pool is to amortize the
memor costs of storing data. However, rather than mitigate the costs of data
duplication, a bulk sharing pool aims to amortize the costs of Java object
headers across the elements in a pool. This is a topic that stretches notions of
how to store data beyond the normal Java box, and so will be discussed, along
with many similar matters, in \autoref{chapter:large-long-lived}.

\section{Resource Pools: Amortizing Allocation Costs}
\label{sec:resource-pools}
\index{Resource Pool}

\index{Amortizing Costs}
A cache can amortize the cost, in time, of fetching or otherwise initializing the
data stored in an object. A sharing pool can amortize the cost, in space, of
storing the same data in many separate objects. In both cases, the data is the
important part of what is stored.

\marginpar{A \textbf{Resource Pool} is a set of interchangeable storage or
external connections that are expensive to construct.} There is a third case,
where one needs to amortize the cost of the allocations, rather than the cost of
initializing or fetching the data that is stored in this object. A resource pool
stores the result of the allocation, not the data. Therefore, the elements of a
resource pool are interchangeable, because it is the storage, not the values that
matter. It is important to note that, though the data values are not the
important part, the elements of the pool are objects, and are thus intended to
store data! A resource pool handles the interesting case where the data is
temporary, but you need, for performance reasons, the objects to live across many
uses. The protocol for using a resource pool then involves reservation, a period
of private use of the fields of the reserved object, followed by a return of that
object to the pool.

Resource pooling only makes sense if the allocations themselves are expensive.
There are several reasons why a Java object can be expensive to allocate.
Creating and zeroing a large array\index{Large Arrays} in each iteration of a
loop can bog down performance. Creating a new key object to determine whether an
value exists in a map can sometimes contribute a great deal to the load of
temporary objects.

\index{Connection Pools}
A more important example of the need for amortizing the time cost of allocation
comes when this Java object is a proxy for resources outside of Java. If your
application accesses a relational database through the JDBC\index{JDBC}
interface, you will experience the need for resource pooling. There are two kinds
of objects that serve as proxies for resources involving database access. First
are the connections to the database. In most operating systems, establishing a
network connection is an expensive proposition. It also involves reservation of
resoures in the database process. Second are the precompiled SQL statements that
your application uses. As with the connections, these involve setup cost, of the
compilation itself, as well as the reservation of memory resources, that the
database uses to cache certain information about the query.

\begin{example}{Per-thread Singleton versus Resource Pool}
\index{Thread-Local Storage}
Your application accesses a remote resource. Why not keep one connection
persistent per thread? What's the point of a resource pool in this case?
\end{example}



\begin{table}
	\centering
	\begin{tabular}{rlll} \toprule
            & cache             & sharing pool & resource pool 
    \\ \cmidrule{2-4}
%    What is Saved & alloc. and data init. time & duplicates &
    %alloc. time 
%    \\
    Addressing the Contents     & by key       & by index & by key
    \\
        Elements Interchangeable?   & no    & no    & yes
    \\
    Multiple Users per Element? & yes   & yes   & no
    \\
    Data Persists Across Uses?  & yes   & yes   & no
    \\ \bottomrule
    \end{tabular}
	\caption{Comparing the charaacteristics of three mechanisms for keeping data
	or objects around for indefinite periods of time.}
	\label{tab:three-deferred-deletions}
\end{table}



%\section{Tradeoffs Gone Wrong: Memory Leaks}

\begin{comment}

\begin{table}
\centering
\begin{tabular}{|l|l|} \hline
\em mechanism & \\ \hline \hline
resource pool & \\ \hline
cache & \\ \hline
sharing pool & (interning)\\ \hline
memoization & \\ \hline
backing store &(externalized memo) \\ \hline
non-OO & (column orientation) \\ \hline 
\end{tabular}
\caption{Lifetime management mechanisms not provided by the Java language that one must implement.}
\label{tab:software-lifetime-management}
\end{table}

\end{comment}